"""
Global-first deployment system for RevNet-Zero models.

Provides multi-region deployment, internationalization support,
compliance frameworks (GDPR, CCPA, PDPA), and edge computing capabilities.
"""

import asyncio
import json
import time
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, field
from enum import Enum
import uuid
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import os

# Cloud provider imports (with fallbacks)
try:
    import boto3
    HAS_AWS = True
except ImportError:
    HAS_AWS = False

try:
    from google.cloud import compute_v1
    HAS_GCP = True  
except ImportError:
    HAS_GCP = False

try:
    from azure.identity import DefaultAzureCredential
    from azure.mgmt.compute import ComputeManagementClient
    HAS_AZURE = True
except ImportError:
    HAS_AZURE = False

import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel

from ..models.reversible_transformer import ReversibleTransformer
from ..optimization.intelligent_cache import IntelligentCacheManager as IntelligentCache

class CloudProvider(Enum):
    """Supported cloud providers."""
    AWS = "aws"
    GCP = "gcp"  
    AZURE = "azure"
    KUBERNETES = "k8s"
    EDGE = "edge"

class ComplianceRegion(Enum):
    """Compliance regions with specific requirements."""
    EU = "eu"  # GDPR
    US = "us"  # CCPA
    APAC = "apac"  # PDPA
    GLOBAL = "global"

@dataclass
class DeploymentConfig:
    """Configuration for global deployment."""
    
    # Model configuration
    model_name: str
    model_version: str = "v1.0"
    
    # Regional settings
    primary_region: str = "us-west-2"
    replica_regions: List[str] = field(default_factory=lambda: ["eu-west-1", "ap-southeast-1"])
    compliance_regions: List[ComplianceRegion] = field(default_factory=lambda: [ComplianceRegion.GLOBAL])
    
    # Infrastructure
    cloud_provider: CloudProvider = CloudProvider.AWS
    instance_types: Dict[str, str] = field(default_factory=lambda: {
        "us-west-2": "g4dn.xlarge",
        "eu-west-1": "g4dn.xlarge", 
        "ap-southeast-1": "g4dn.xlarge"
    })
    
    # Scaling configuration
    min_instances: int = 1
    max_instances: int = 10
    target_utilization: float = 0.7
    
    # Performance requirements
    max_latency_ms: float = 500
    min_throughput_rps: float = 100
    
    # Security and compliance
    encryption_at_rest: bool = True
    encryption_in_transit: bool = True
    audit_logging: bool = True
    data_residency_strict: bool = True
    
    # Internationalization
    supported_languages: List[str] = field(default_factory=lambda: ["en", "es", "fr", "de", "ja", "zh"])
    
    # Edge deployment
    edge_locations: List[str] = field(default_factory=list)
    edge_model_compression: str = "quantization"  # "quantization", "distillation", "pruning"

@dataclass
class RegionStatus:
    """Status of deployment in a specific region."""
    
    region: str
    provider: CloudProvider
    status: str  # "deploying", "healthy", "degraded", "failed"
    instances: int
    cpu_utilization: float
    memory_utilization: float
    requests_per_second: float
    latency_p99_ms: float
    last_health_check: float
    compliance_status: Dict[str, bool] = field(default_factory=dict)

class GlobalLoadBalancer:
    """Intelligent global load balancer with latency-based routing."""
    
    def __init__(self, deployment_config: DeploymentConfig):
        self.config = deployment_config
        self.region_weights: Dict[str, float] = {}
        self.health_status: Dict[str, RegionStatus] = {}
        self.latency_matrix: Dict[Tuple[str, str], float] = {}
        
        # Initialize region weights
        self._initialize_region_weights()
    
    def _initialize_region_weights(self):
        """Initialize routing weights for regions."""
        total_regions = len(self.config.replica_regions) + 1
        base_weight = 1.0 / total_regions
        
        # Primary region gets slight preference
        self.region_weights[self.config.primary_region] = base_weight * 1.2
        
        for region in self.config.replica_regions:
            self.region_weights[region] = base_weight * 0.9
        
        # Normalize weights
        total_weight = sum(self.region_weights.values())
        for region in self.region_weights:
            self.region_weights[region] /= total_weight
    
    def route_request(self, client_location: str, request_metadata: Dict) -> str:
        """
        Route request to optimal region.
        
        Args:
            client_location: Client's geographic location
            request_metadata: Request metadata for routing decisions
            
        Returns:
            optimal_region: Best region to handle the request
        """
        # Get healthy regions
        healthy_regions = [region for region, status in self.health_status.items() 
                          if status.status == "healthy"]
        
        if not healthy_regions:
            # Fallback to primary region
            return self.config.primary_region
        
        # Calculate routing scores
        region_scores = {}
        
        for region in healthy_regions:
            score = 0.0
            
            # Latency score (lower is better)
            latency = self.latency_matrix.get((client_location, region), 1000)
            latency_score = max(0, 1 - (latency / 1000))  # Normalize to 0-1
            score += latency_score * 0.4
            
            # Load score (lower utilization is better)
            status = self.health_status[region]
            load_score = max(0, 1 - status.cpu_utilization)
            score += load_score * 0.3
            
            # Weight score (configured preferences)
            weight_score = self.region_weights.get(region, 0)
            score += weight_score * 0.2
            
            # Compliance score
            compliance_score = self._calculate_compliance_score(region, request_metadata)
            score += compliance_score * 0.1
            
            region_scores[region] = score
        
        # Select best region
        return max(region_scores.items(), key=lambda x: x[1])[0]
    
    def _calculate_compliance_score(self, region: str, request_metadata: Dict) -> float:
        """Calculate compliance score for region."""
        if region not in self.health_status:
            return 0.0
            
        status = self.health_status[region]
        compliance_checks = status.compliance_status
        
        # Check data residency requirements
        client_region = request_metadata.get('client_region', 'unknown')
        if self.config.data_residency_strict:
            if client_region.startswith('eu') and not region.startswith('eu'):
                return 0.0  # GDPR compliance violation
        
        # Overall compliance score
        if compliance_checks:
            return sum(compliance_checks.values()) / len(compliance_checks)
        
        return 1.0  # Assume compliant if no specific checks

class ComplianceManager:
    """Manages compliance requirements across regions."""
    
    def __init__(self, config: DeploymentConfig):
        self.config = config
        self.compliance_rules = self._load_compliance_rules()
        
    def _load_compliance_rules(self) -> Dict[ComplianceRegion, Dict]:
        """Load compliance rules for different regions."""
        return {
            ComplianceRegion.EU: {
                'gdpr_required': True,
                'data_processing_consent': True,
                'right_to_erasure': True,
                'data_portability': True,
                'privacy_by_design': True,
                'retention_limits': {'max_days': 365 * 7},  # 7 years max
                'encryption_required': True
            },
            ComplianceRegion.US: {
                'ccpa_required': True,
                'consumer_rights': True,
                'opt_out_required': True,
                'data_sales_disclosure': True,
                'retention_limits': {'max_days': 365 * 5},  # 5 years max
                'encryption_recommended': True
            },
            ComplianceRegion.APAC: {
                'pdpa_required': True,
                'consent_management': True,
                'data_localization': True,
                'breach_notification': True,
                'retention_limits': {'max_days': 365 * 3},  # 3 years max
                'cross_border_restrictions': True
            },
            ComplianceRegion.GLOBAL: {
                'basic_privacy': True,
                'encryption_in_transit': True,
                'access_logging': True,
                'retention_limits': {'max_days': 365 * 2}  # 2 years max
            }
        }
    
    def validate_deployment(self, region: str, deployment_spec: Dict) -> Tuple[bool, List[str]]:
        """
        Validate deployment against compliance requirements.
        
        Args:
            region: Target deployment region
            deployment_spec: Deployment specification
            
        Returns:
            is_compliant: Whether deployment meets compliance
            violations: List of compliance violations
        """
        violations = []
        
        # Determine applicable compliance regions
        applicable_regions = self._get_applicable_compliance_regions(region)
        
        for compliance_region in applicable_regions:
            rules = self.compliance_rules[compliance_region]
            
            # Check encryption requirements
            if rules.get('gdpr_required') or rules.get('encryption_required'):
                if not deployment_spec.get('encryption_at_rest'):
                    violations.append(f"Encryption at rest required for {compliance_region.value}")
                if not deployment_spec.get('encryption_in_transit'):
                    violations.append(f"Encryption in transit required for {compliance_region.value}")
            
            # Check data retention
            if 'retention_limits' in rules:
                max_retention = rules['retention_limits']['max_days']
                deployment_retention = deployment_spec.get('data_retention_days', 0)
                if deployment_retention > max_retention:
                    violations.append(f"Data retention exceeds {max_retention} days for {compliance_region.value}")
            
            # Check audit logging
            if rules.get('access_logging') or rules.get('gdpr_required'):
                if not deployment_spec.get('audit_logging'):
                    violations.append(f"Audit logging required for {compliance_region.value}")
            
            # Check data localization
            if rules.get('data_localization') or rules.get('cross_border_restrictions'):
                if deployment_spec.get('cross_region_replication'):
                    violations.append(f"Cross-border data transfer restricted for {compliance_region.value}")
        
        return len(violations) == 0, violations
    
    def _get_applicable_compliance_regions(self, region: str) -> List[ComplianceRegion]:
        """Get applicable compliance regions for a geographic region."""
        applicable = [ComplianceRegion.GLOBAL]  # Always applicable
        
        if region.startswith('eu'):
            applicable.append(ComplianceRegion.EU)
        elif region.startswith('us'):
            applicable.append(ComplianceRegion.US)
        elif region.startswith('ap'):
            applicable.append(ComplianceRegion.APAC)
            
        return applicable
    
    def generate_privacy_notice(self, language: str = 'en') -> str:
        """Generate privacy notice for the specified language."""
        privacy_templates = {
            'en': """
# Privacy Notice - RevNet-Zero AI Service

## Data Collection and Use
We collect and process data to provide AI inference services. Data is processed in accordance with applicable privacy laws including GDPR, CCPA, and PDPA.

## Your Rights
- Right to access your data
- Right to correct inaccuracies  
- Right to delete your data
- Right to data portability
- Right to opt-out of processing

## Data Security
All data is encrypted in transit and at rest using industry-standard encryption.

## Contact
For privacy inquiries: privacy@revnet-zero.org
            """,
            'es': """
# Aviso de Privacidad - Servicio de IA RevNet-Zero

## RecolecciÃ³n y Uso de Datos
Recopilamos y procesamos datos para proporcionar servicios de inferencia de IA...
            """,
            'fr': """
# Avis de ConfidentialitÃ© - Service IA RevNet-Zero

## Collecte et Utilisation des DonnÃ©es
Nous collectons et traitons les donnÃ©es pour fournir des services d'infÃ©rence IA...
            """,
            'de': """
# Datenschutzhinweis - RevNet-Zero KI-Service

## Datenerhebung und -verwendung
Wir erheben und verarbeiten Daten zur Bereitstellung von KI-Inferenz-Diensten...
            """,
            'ja': """
# ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼é€šçŸ¥ - RevNet-Zero AIã‚µãƒ¼ãƒ“ã‚¹

## ãƒ‡ãƒ¼ã‚¿ã®åŽé›†ã¨ä½¿ç”¨
AIã®æŽ¨è«–ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚’åŽé›†ãƒ»å‡¦ç†ã—ã¾ã™...
            """,
            'zh': """
# éšç§å£°æ˜Ž - RevNet-Zero AI æœåŠ¡

## æ•°æ®æ”¶é›†å’Œä½¿ç”¨
æˆ‘ä»¬æ”¶é›†å’Œå¤„ç†æ•°æ®ä»¥æä¾›AIæŽ¨ç†æœåŠ¡...
            """
        }
        
        return privacy_templates.get(language, privacy_templates['en'])

class GlobalDeploymentManager:
    """Main orchestrator for global RevNet-Zero deployments."""
    
    def __init__(self, config: DeploymentConfig):
        self.config = config
        self.load_balancer = GlobalLoadBalancer(config)
        self.compliance_manager = ComplianceManager(config)
        self.deployment_id = str(uuid.uuid4())
        
        # State tracking
        self.region_deployments: Dict[str, Any] = {}
        self.deployment_status = "initializing"
        
        # Cloud provider clients
        self.cloud_clients = self._initialize_cloud_clients()
        
        # Set up logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def _initialize_cloud_clients(self) -> Dict[CloudProvider, Any]:
        """Initialize cloud provider clients."""
        clients = {}
        
        if HAS_AWS and self.config.cloud_provider == CloudProvider.AWS:
            clients[CloudProvider.AWS] = {
                'ec2': boto3.client('ec2'),
                'elbv2': boto3.client('elbv2'),
                'autoscaling': boto3.client('autoscaling')
            }
        
        if HAS_GCP and self.config.cloud_provider == CloudProvider.GCP:
            clients[CloudProvider.GCP] = {
                'compute': compute_v1.InstancesClient()
            }
        
        if HAS_AZURE and self.config.cloud_provider == CloudProvider.AZURE:
            credential = DefaultAzureCredential()
            clients[CloudProvider.AZURE] = {
                'compute': ComputeManagementClient(credential, 'subscription-id')
            }
        
        return clients
    
    async def deploy_globally(self, model: ReversibleTransformer) -> Dict[str, Any]:
        """
        Deploy model globally across all configured regions.
        
        Args:
            model: RevNet-Zero model to deploy
            
        Returns:
            deployment_info: Deployment status and endpoints
        """
        self.logger.info(f"ðŸŒ Starting global deployment: {self.deployment_id}")
        
        deployment_info = {
            'deployment_id': self.deployment_id,
            'status': 'deploying',
            'regions': {},
            'load_balancer_endpoint': None,
            'compliance_status': {}
        }
        
        # Validate compliance for all regions
        compliance_results = await self._validate_global_compliance()
        deployment_info['compliance_status'] = compliance_results
        
        # Deploy to primary region first
        primary_result = await self._deploy_to_region(
            self.config.primary_region, model, is_primary=True
        )
        deployment_info['regions'][self.config.primary_region] = primary_result
        
        # Deploy to replica regions concurrently
        replica_tasks = []
        for region in self.config.replica_regions:
            task = self._deploy_to_region(region, model, is_primary=False)
            replica_tasks.append(task)
        
        # Wait for all replica deployments
        replica_results = await asyncio.gather(*replica_tasks, return_exceptions=True)
        
        for i, result in enumerate(replica_results):
            region = self.config.replica_regions[i]
            if isinstance(result, Exception):
                self.logger.error(f"Failed to deploy to {region}: {result}")
                deployment_info['regions'][region] = {'status': 'failed', 'error': str(result)}
            else:
                deployment_info['regions'][region] = result
        
        # Set up global load balancer
        lb_endpoint = await self._setup_global_load_balancer()
        deployment_info['load_balancer_endpoint'] = lb_endpoint
        
        # Deploy to edge locations if configured
        if self.config.edge_locations:
            edge_results = await self._deploy_to_edge_locations(model)
            deployment_info['edge_deployments'] = edge_results
        
        deployment_info['status'] = 'deployed'
        self.deployment_status = 'deployed'
        
        # Start health monitoring
        asyncio.create_task(self._start_health_monitoring())
        
        self.logger.info(f"âœ… Global deployment complete: {lb_endpoint}")
        return deployment_info
    
    async def _validate_global_compliance(self) -> Dict[str, Any]:
        """Validate compliance across all target regions."""
        compliance_results = {}
        
        deployment_spec = {
            'encryption_at_rest': self.config.encryption_at_rest,
            'encryption_in_transit': self.config.encryption_in_transit,
            'audit_logging': self.config.audit_logging,
            'data_retention_days': 730,  # 2 years default
            'cross_region_replication': len(self.config.replica_regions) > 0
        }
        
        all_regions = [self.config.primary_region] + self.config.replica_regions
        
        for region in all_regions:
            is_compliant, violations = self.compliance_manager.validate_deployment(
                region, deployment_spec
            )
            
            compliance_results[region] = {
                'compliant': is_compliant,
                'violations': violations,
                'applicable_regulations': self.compliance_manager._get_applicable_compliance_regions(region)
            }
            
            if not is_compliant:
                self.logger.warning(f"âš ï¸ Compliance issues in {region}: {violations}")
        
        return compliance_results
    
    async def _deploy_to_region(self, region: str, model: ReversibleTransformer, is_primary: bool) -> Dict[str, Any]:
        """Deploy model to a specific region."""
        self.logger.info(f"ðŸ“ Deploying to region: {region} (primary: {is_primary})")
        
        try:
            # Create regional deployment specification
            deployment_spec = {
                'region': region,
                'instance_type': self.config.instance_types.get(region, 'g4dn.xlarge'),
                'min_instances': self.config.min_instances,
                'max_instances': self.config.max_instances,
                'model_config': self._serialize_model_config(model),
                'is_primary': is_primary
            }
            
            # Deploy infrastructure based on cloud provider
            if self.config.cloud_provider == CloudProvider.AWS:
                result = await self._deploy_aws_region(region, deployment_spec)
            elif self.config.cloud_provider == CloudProvider.GCP:
                result = await self._deploy_gcp_region(region, deployment_spec)
            elif self.config.cloud_provider == CloudProvider.AZURE:
                result = await self._deploy_azure_region(region, deployment_spec)
            else:
                result = await self._deploy_k8s_region(region, deployment_spec)
            
            # Set up regional monitoring
            await self._setup_regional_monitoring(region)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to deploy to {region}: {e}")
            raise e
    
    async def _deploy_aws_region(self, region: str, deployment_spec: Dict) -> Dict[str, Any]:
        """Deploy to AWS region."""
        # This is a simplified implementation - in practice would use CloudFormation/CDK
        
        # Create auto-scaling group
        asg_name = f"revnet-zero-{self.deployment_id}-{region}"
        
        # Launch template would include:
        # - AMI with RevNet-Zero pre-installed
        # - Security groups
        # - IAM roles
        # - User data script for model loading
        
        endpoint_url = f"https://api-{region}.revnet-zero.ai/{self.deployment_id}"
        
        return {
            'status': 'deployed',
            'endpoint': endpoint_url,
            'auto_scaling_group': asg_name,
            'instance_count': self.config.min_instances,
            'deployment_time': time.time()
        }
    
    async def _deploy_gcp_region(self, region: str, deployment_spec: Dict) -> Dict[str, Any]:
        """Deploy to GCP region."""
        # Simplified GCP deployment
        endpoint_url = f"https://api-{region}.revnet-zero.ai/{self.deployment_id}"
        
        return {
            'status': 'deployed',
            'endpoint': endpoint_url,
            'managed_instance_group': f"revnet-zero-mig-{region}",
            'instance_count': self.config.min_instances,
            'deployment_time': time.time()
        }
    
    async def _deploy_azure_region(self, region: str, deployment_spec: Dict) -> Dict[str, Any]:
        """Deploy to Azure region."""
        # Simplified Azure deployment
        endpoint_url = f"https://api-{region}.revnet-zero.ai/{self.deployment_id}"
        
        return {
            'status': 'deployed',
            'endpoint': endpoint_url,
            'scale_set': f"revnet-zero-vmss-{region}",
            'instance_count': self.config.min_instances,
            'deployment_time': time.time()
        }
    
    async def _deploy_k8s_region(self, region: str, deployment_spec: Dict) -> Dict[str, Any]:
        """Deploy to Kubernetes cluster."""
        # Simplified K8s deployment
        endpoint_url = f"https://api-{region}.revnet-zero.ai/{self.deployment_id}"
        
        return {
            'status': 'deployed',
            'endpoint': endpoint_url,
            'deployment': f"revnet-zero-deployment-{region}",
            'service': f"revnet-zero-service-{region}",
            'replicas': self.config.min_instances,
            'deployment_time': time.time()
        }
    
    async def _deploy_to_edge_locations(self, model: ReversibleTransformer) -> Dict[str, Any]:
        """Deploy compressed models to edge locations."""
        edge_results = {}
        
        # Compress model for edge deployment
        compressed_model = await self._compress_model_for_edge(model)
        
        for edge_location in self.config.edge_locations:
            try:
                # Deploy to edge (CDN edge, IoT gateway, mobile, etc.)
                result = await self._deploy_edge_instance(edge_location, compressed_model)
                edge_results[edge_location] = result
                
            except Exception as e:
                self.logger.error(f"Failed to deploy to edge {edge_location}: {e}")
                edge_results[edge_location] = {'status': 'failed', 'error': str(e)}
        
        return edge_results
    
    async def _compress_model_for_edge(self, model: ReversibleTransformer) -> Any:
        """Compress model for edge deployment."""
        if self.config.edge_model_compression == "quantization":
            # Apply 8-bit quantization
            quantized_model = torch.quantization.quantize_dynamic(
                model, {torch.nn.Linear}, dtype=torch.qint8
            )
            return quantized_model
        
        elif self.config.edge_model_compression == "distillation":
            # Knowledge distillation (simplified)
            # In practice would train a smaller student model
            return model
            
        elif self.config.edge_model_compression == "pruning":
            # Weight pruning (simplified)
            return model
        
        return model
    
    async def _deploy_edge_instance(self, edge_location: str, compressed_model: Any) -> Dict[str, Any]:
        """Deploy model instance to edge location."""
        # Simplified edge deployment
        return {
            'status': 'deployed',
            'location': edge_location,
            'model_size_mb': 50,  # Compressed size
            'latency_ms': 10,     # Expected edge latency
            'deployment_time': time.time()
        }
    
    async def _setup_global_load_balancer(self) -> str:
        """Set up global load balancer."""
        # In practice would configure:
        # - AWS CloudFront + ALB
        # - GCP Cloud Load Balancer
        # - Azure Front Door
        # - Cloudflare for DNS-based routing
        
        lb_endpoint = f"https://api.revnet-zero.ai/{self.deployment_id}"
        
        # Configure routing rules
        routing_config = {
            'health_checks': True,
            'latency_based_routing': True,
            'geographic_routing': True,
            'failover_enabled': True,
            'ssl_termination': True
        }
        
        self.logger.info(f"ðŸ”— Global load balancer configured: {lb_endpoint}")
        return lb_endpoint
    
    async def _setup_regional_monitoring(self, region: str):
        """Set up monitoring for a specific region."""
        # Configure metrics, alerts, and dashboards
        monitoring_config = {
            'metrics': ['latency', 'throughput', 'error_rate', 'cpu_usage', 'memory_usage'],
            'alerts': {
                'high_latency': {'threshold': self.config.max_latency_ms, 'enabled': True},
                'low_throughput': {'threshold': self.config.min_throughput_rps, 'enabled': True},
                'high_error_rate': {'threshold': 0.05, 'enabled': True}
            },
            'dashboards': ['performance', 'compliance', 'costs']
        }
        
        self.logger.info(f"ðŸ“Š Monitoring configured for region: {region}")
    
    async def _start_health_monitoring(self):
        """Start continuous health monitoring across all regions."""
        while self.deployment_status == 'deployed':
            try:
                # Check health of all regions
                all_regions = [self.config.primary_region] + self.config.replica_regions
                
                for region in all_regions:
                    status = await self._check_region_health(region)
                    self.load_balancer.health_status[region] = status
                
                # Update load balancer weights based on health
                self._update_load_balancer_weights()
                
                # Sleep before next check
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                self.logger.error(f"Health monitoring error: {e}")
                await asyncio.sleep(60)  # Longer sleep on error
    
    async def _check_region_health(self, region: str) -> RegionStatus:
        """Check health status of a specific region."""
        # Simplified health check - in practice would call actual endpoints
        
        # Simulate health metrics
        import random
        
        status = RegionStatus(
            region=region,
            provider=self.config.cloud_provider,
            status="healthy",
            instances=random.randint(self.config.min_instances, self.config.max_instances),
            cpu_utilization=random.uniform(0.3, 0.8),
            memory_utilization=random.uniform(0.4, 0.7),
            requests_per_second=random.uniform(50, 200),
            latency_p99_ms=random.uniform(100, 400),
            last_health_check=time.time(),
            compliance_status={
                'encryption': True,
                'audit_logging': True,
                'data_residency': True
            }
        )
        
        return status
    
    def _update_load_balancer_weights(self):
        """Update load balancer weights based on current health."""
        total_capacity = 0
        region_capacities = {}
        
        # Calculate capacity for each healthy region
        for region, status in self.load_balancer.health_status.items():
            if status.status == "healthy":
                # Capacity based on utilization (lower utilization = higher capacity)
                capacity = (1 - status.cpu_utilization) * status.instances
                region_capacities[region] = capacity
                total_capacity += capacity
        
        # Update weights
        if total_capacity > 0:
            for region in region_capacities:
                self.load_balancer.region_weights[region] = region_capacities[region] / total_capacity
    
    def _serialize_model_config(self, model: ReversibleTransformer) -> Dict[str, Any]:
        """Serialize model configuration for deployment."""
        if hasattr(model, 'get_model_info'):
            return model.get_model_info()
        
        return {
            'model_type': 'reversible_transformer',
            'parameters': sum(p.numel() for p in model.parameters()),
            'config': 'serialized_config'  # In practice would serialize actual config
        }
    
    def get_deployment_status(self) -> Dict[str, Any]:
        """Get current deployment status."""
        return {
            'deployment_id': self.deployment_id,
            'status': self.deployment_status,
            'regions': {
                region: status.__dict__ if hasattr(status, '__dict__') else status
                for region, status in self.load_balancer.health_status.items()
            },
            'load_balancer_weights': self.load_balancer.region_weights,
            'compliance_status': 'compliant'  # Simplified
        }
    
    async def scale_deployment(self, region: str, target_instances: int) -> Dict[str, Any]:
        """Scale deployment in a specific region."""
        self.logger.info(f"ðŸ“ˆ Scaling {region} to {target_instances} instances")
        
        # In practice would call cloud provider APIs
        result = {
            'region': region,
            'previous_instances': self.config.min_instances,
            'target_instances': target_instances,
            'scaling_time': time.time(),
            'status': 'scaling'
        }
        
        # Simulate scaling delay
        await asyncio.sleep(2)
        result['status'] = 'completed'
        
        return result
    
    async def cleanup_deployment(self):
        """Clean up global deployment resources."""
        self.logger.info(f"ðŸ§¹ Cleaning up deployment: {self.deployment_id}")
        
        self.deployment_status = 'terminating'
        
        # Clean up resources in all regions
        all_regions = [self.config.primary_region] + self.config.replica_regions
        
        cleanup_tasks = [self._cleanup_region(region) for region in all_regions]
        await asyncio.gather(*cleanup_tasks, return_exceptions=True)
        
        # Clean up global load balancer
        await self._cleanup_load_balancer()
        
        self.deployment_status = 'terminated'
        self.logger.info("âœ… Deployment cleanup complete")
    
    async def _cleanup_region(self, region: str):
        """Clean up resources in a specific region."""
        # In practice would delete:
        # - Auto-scaling groups
        # - Load balancers  
        # - Security groups
        # - IAM roles
        # etc.
        
        self.logger.info(f"Cleaned up region: {region}")
    
    async def _cleanup_load_balancer(self):
        """Clean up global load balancer resources."""
        self.logger.info("Cleaned up global load balancer")

# Factory functions
def create_global_deployment(
    model_name: str,
    regions: List[str] = None,
    cloud_provider: CloudProvider = CloudProvider.AWS,
    compliance_regions: List[ComplianceRegion] = None
) -> GlobalDeploymentManager:
    """
    Create a global deployment configuration.
    
    Args:
        model_name: Name of the model to deploy
        regions: List of regions to deploy to
        cloud_provider: Cloud provider to use
        compliance_regions: Compliance requirements
        
    Returns:
        deployment_manager: Configured global deployment manager
    """
    regions = regions or ["us-west-2", "eu-west-1", "ap-southeast-1"]
    compliance_regions = compliance_regions or [ComplianceRegion.GLOBAL]
    
    config = DeploymentConfig(
        model_name=model_name,
        primary_region=regions[0],
        replica_regions=regions[1:],
        cloud_provider=cloud_provider,
        compliance_regions=compliance_regions
    )
    
    return GlobalDeploymentManager(config)

# CLI Interface
async def deploy_model_globally(
    model: ReversibleTransformer,
    config_path: Optional[str] = None
) -> Dict[str, Any]:
    """
    CLI function to deploy model globally.
    
    Args:
        model: Model to deploy
        config_path: Path to deployment configuration
        
    Returns:
        deployment_result: Deployment information
    """
    if config_path:
        with open(config_path, 'r') as f:
            config_dict = json.load(f)
        config = DeploymentConfig(**config_dict)
    else:
        config = DeploymentConfig(model_name="revnet-zero-model")
    
    manager = GlobalDeploymentManager(config)
    result = await manager.deploy_globally(model)
    
    return result

# Export
__all__ = [
    'GlobalDeploymentManager',
    'DeploymentConfig',
    'CloudProvider',
    'ComplianceRegion',
    'ComplianceManager',
    'GlobalLoadBalancer',
    'create_global_deployment',
    'deploy_model_globally'
]